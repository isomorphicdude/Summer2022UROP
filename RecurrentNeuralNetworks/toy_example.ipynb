{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A toy example  \n",
    "\n",
    "In this notebook, we will use vanilla LSTM recurrent neural networks to learn our model.  \n",
    "\n",
    "*Note: In this notebook, we will use the tensorflow probability library, which needs to be installed as it's not part of tensorflow*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import sys; sys.path.insert(0, '..')\n",
    "from data.data_generator import *\n",
    "from preprocess import *\n",
    "from window_data import *\n",
    "\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# Hide GPU from visible devices\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data  \n",
    "\n",
    "We get data using the first model (also the simplest). We also only use `10` samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "total = generateData(model1,\n",
    "        num_data = 10,\n",
    "        init_sty = 'random',\n",
    "        times = (0, 20),\n",
    "        params = {'no. of prey': N, \n",
    "    'kappa for prey': 0.5, \n",
    "    'attraction of prey a': 1, \n",
    "    'repulsion of prey b_1': 1, \n",
    "    'repulsion of pred b_2': 0.07, \n",
    "    'attraction of pred c': 10, \n",
    "    'exponent of dist pred p': 1.2},\n",
    "        steps = 1000,\n",
    "        second_order = False,\n",
    "        method = 'rk2',\n",
    "        return_vel = False,\n",
    "        cores = 8,\n",
    "        flattened=False)\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end-start} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot showing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiPlot([total[0][1], 20/1000, 10], sample_points =[0,0.5,2,4,6,8,10],\n",
    "            axis_lim = None, second_order = False, quiver=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has the shape `(batch, times, individuals, coordinates)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([total[i][1] for i in range(len(total))])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use one initial condition for this experiment, as our naive implementation only works well with one time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[0]\n",
    "train_ds, valid_ds, test_ds = getDatasets(data, scaling = False, return_ndarray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an experiment, change to `input_width=900, label_width=100, shift=100` and change the data above (otherwise there is not enough data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window1 = WindowData(input_width=300, label_width=10, shift=10,\n",
    "                    train_ds=train_ds, val_ds=valid_ds, test_ds=test_ds)\n",
    "print(window1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = window1.make_train()\n",
    "valid_ds = window1.make_val()\n",
    "test_ds = window1.make_test()\n",
    "\n",
    "print(train_ds.element_spec)\n",
    "print(valid_ds.element_spec)\n",
    "print(test_ds.element_spec)\n",
    "print(window1.num_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A naive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is that for data of shape `(batch, times, individuals)`, we pass to an LSTM layer after `embedding` it in some way (the idea is similar to one-hot encoding of integer/categorical values), where it has output shape `(batch, times, length of concatenated embeddings)`, we can then produce a prediction at a single future time step of the shape `(batch, 1, individuals)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn import *\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Input(shape=(window1.input_width,21,2)),\n",
    "                            embedder((window1.input_width,21,2), 64, batch_size=32)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 64\n",
    "\n",
    "lstm_model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((window1.input_width,21,2)),\n",
    "    embedder((window1.input_width,21,2), embedding_size, batch_size=32),\n",
    "    tf.keras.layers.LSTM(2*embedding_size, return_sequences=False),\n",
    "    # 5 outputs for each trajectory as it's bivariate normal\n",
    "    # there are window1.num_points trajectories (21 in this case)\n",
    "    # so we need 5*21 outputs at each time step\n",
    "    # there are window1.label_width time steps (5 in this case)\n",
    "    # so we have 5*21*5 outputs from Dense layer\n",
    "    # first two 21 blocks are means, last 21*3 block \n",
    "    # form the lower-tril matrix (consecutive 3 for each coord)\n",
    "    # final output shape should be (batch, 5, 21, 2)\n",
    "    tf.keras.layers.Dense(window1.label_width * window1.num_points * 5, activation='linear'),\n",
    "    tf.keras.layers.Reshape((window1.label_width, window1.num_points, 5)),\n",
    "    # the loc should be (5, 21, 2)\n",
    "    # the scale_tril should be (5, 21, 3)\n",
    "    tfpl.DistributionLambda(lambda x: tfd.MultivariateNormalTriL(\n",
    "                            loc=x[..., :2], \n",
    "                            scale_tril=tfp.math.fill_triangular(x[...,2:])\n",
    "                            )\n",
    "                           )\n",
    "])\n",
    "\n",
    "lstm_model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going on, we take a sample from our dataset and pass it through the model to verify the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    x_sample = x\n",
    "    y_sample = y\n",
    "    print(\"The log probability shape is:\")\n",
    "    print(lstm_model_1(x).log_prob(y).shape)\n",
    "    print(\"The true value's shape is:\")\n",
    "    print(y.shape)\n",
    "    print(\"After reduction the probability shape is:\")\n",
    "    print(tf.reduce_mean(lstm_model_1(x).log_prob(y), axis=1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define also a custom loss function that computes the negative log likelihood over the time steps of prediction.  \n",
    "\n",
    "Recall that we would like to sum over the prediction time steps, which is the second axis in this case   \n",
    "\n",
    "$$\n",
    "L^i = - \\sum_{t=T_{obs}+1}^{T_{end}} \\log (\\Pr((x_i,y_i)^t \\mid \\mu_i^t, \\sigma_i^t, \\rho_i^t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negLog(y_true, y_pred):\n",
    "    return -tf.reduce_sum(y_pred.log_prob(y_true), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original paper, the authors used various metrics to evaluate the model's performance. One of those is the average displacement error, which is the mean square error (MSE) over all estimated points of a trajectory and the true points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADE(y_true, y_pred):\n",
    "    return tf.reduce_sum((y_true-y_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `RMSProp` as in the paper to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_1.compile(loss=negLog, \n",
    "                    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.003),\n",
    "                    metrics=[ADE]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_1.fit(train_ds, epochs=50, validation_data=valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the model by sampling from the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm_model_1(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_trajec = y_sample.numpy()[0]\n",
    "pred_trajec = y_pred.sample().numpy()[0]\n",
    "print(pred_trajec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiPlot([pred_trajec, 1, 10], sample_points =[0,1,2,3,4],\n",
    "            axis_lim = None, second_order = False, quiver=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiPlot([true_trajec, 1, 10], sample_points =[0,1,2,3,4],\n",
    "            axis_lim = None, second_order = False, quiver=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The average displacement error is {ADE(y_sample, y_pred.sample()).numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63bf7c73efbaa60a9891fdddd1e96dd0cc596469d20228077150d640c222586"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
