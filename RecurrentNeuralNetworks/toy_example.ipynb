{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A toy example  \n",
    "\n",
    "In this notebook, we will use vanilla LSTM recurrent neural networks to learn our model.  \n",
    "\n",
    "*Note: In this notebook, we will use the tensorflow probability library, which needs to be installed as it's not part of tensorflow*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import sys; sys.path.insert(0, '..')\n",
    "from data.data_generator import *\n",
    "from preprocess import *\n",
    "from window_data import *\n",
    "\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data  \n",
    "\n",
    "We get data using the first model (also the simplest). We also only use `10` samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to use multiprocessing...\n",
      "Multiprocessing successful.\n",
      "Time taken: 1.225876808166504 seconds.\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "total = generateData(model1,\n",
    "        num_data = 10,\n",
    "        init_sty = 'random',\n",
    "        times = (0, 20),\n",
    "        params = {'no. of prey': N, \n",
    "    'kappa for prey': 0.5, \n",
    "    'attraction of prey a': 1, \n",
    "    'repulsion of prey b_1': 1, \n",
    "    'repulsion of pred b_2': 0.07, \n",
    "    'attraction of pred c': 10, \n",
    "    'exponent of dist pred p': 1.2},\n",
    "        steps = 1000,\n",
    "        second_order = False,\n",
    "        method = 'rk2',\n",
    "        return_vel = False,\n",
    "        cores = 8,\n",
    "        flattened=False)\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end-start} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot showing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiPlot([total[0][1], 20/1000, 10], sample_points =[0,0.5,2,4,6,8,10],\n",
    "#             axis_lim = None, second_order = False, quiver=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has the shape `(batch, times, individuals, coordinates)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000, 21, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([total[i][1] for i in range(len(total))])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use one initial condition for this experiment, as our naive implementation only works well with one time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 21, 2) (100, 21, 2) (100, 21, 2)\n"
     ]
    }
   ],
   "source": [
    "data = data[0]\n",
    "train_ds, valid_ds, test_ds = getDatasets(data, scaling = False, return_ndarray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an experiment, change to `input_width=900, label_width=100, shift=100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total window size: 15\n",
      "Input indices: [0 1 2 3 4 5 6 7 8 9]\n",
      "Label indices: [10 11 12 13 14]\n",
      "Label start: 10\n",
      "Input slice: slice(0, 10, None)\n",
      "Label slice: slice(10, None, None)\n"
     ]
    }
   ],
   "source": [
    "window1 = WindowData(input_width=10, label_width=5, shift=5,\n",
    "                    train_ds=train_ds, val_ds=valid_ds, test_ds=test_ds)\n",
    "print(window1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "(TensorSpec(shape=(None, 10, 21, 2), dtype=tf.float32, name=None), TensorSpec(shape=(None, 5, 21, 2), dtype=tf.float32, name=None))\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 23:50:49.859946: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-14 23:50:49.860048: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_ds = window1.make_train()\n",
    "valid_ds = window1.make_val()\n",
    "test_ds = window1.make_test()\n",
    "\n",
    "print(train_ds.element_spec)\n",
    "print(window1.num_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A naive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is that for data of shape `(batch, times, individuals)`, we pass to an LSTM layer after `embedding` it in some way (the idea is similar to one-hot encoding of integer/categorical values), where it has output shape `(batch, times, length of concatenated embeddings)`, we can then produce a prediction at a single future time step of the shape `(batch, 1, individuals)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedder (embedder)         (32, 10, 1344)            861504    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 861,504\n",
      "Trainable params: 861,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from rnn import *\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Input(shape=(10,21,2)),\n",
    "                            embedder((10,21,2), 64, batch_size=32)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float64, numpy=\n",
       "array([[ 1.31127106,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.46805656, -1.09843779,  0.        ,  0.        ],\n",
       "       [ 0.99597515, -0.07251197,  0.03541874,  0.        ],\n",
       "       [ 1.08537411,  0.17744395,  0.07478798,  0.46986297]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 4\n",
    "coeffs = tf.constant(np.random.normal(0, 1, int(n*(n+1)/2)), dtype=tf.float64)\n",
    "lower_diag = tfp.math.fill_triangular(coeffs)\n",
    "lower_diag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedder_9 (embedder)       (32, 10, 1344)            861504    \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (32, 128)                 754176    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (32, 525)                 67725     \n",
      "                                                                 \n",
      " reshape_7 (Reshape)         (32, 5, 21, 5)            0         \n",
      "                                                                 \n",
      " distribution_lambda (Distri  ((32, 5, 21, 2),         0         \n",
      " butionLambda)                (32, 5, 21, 2))                    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,683,405\n",
      "Trainable params: 1,683,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 64\n",
    "\n",
    "lstm_model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((10,21,2)),\n",
    "    embedder((10,21,2), embedding_size, batch_size=32),\n",
    "    tf.keras.layers.LSTM(2*embedding_size, return_sequences=False),\n",
    "    # 5 outputs for each trajectory as it's bivariate normal\n",
    "    # there are window1.num_points trajectories (21 in this case)\n",
    "    # so we need 5*21 outputs at each time step\n",
    "    # there are window1.label_width time steps (5 in this case)\n",
    "    # so we have 5*21*5 outputs from Dense layer\n",
    "    # first two 21 blocks are means, last 21*3 block \n",
    "    # form the lower-tril matrix (consecutive 3 for each coord)\n",
    "    # final output shape should be (batch, 5, 21, 2)\n",
    "    tf.keras.layers.Dense(5*window1.num_points*5, activation='linear'),\n",
    "    tf.keras.layers.Reshape((5, window1.num_points, 5)),\n",
    "    # the loc should be (5, 21, 2)\n",
    "    # the scale_tril should be (5, 21, 2, 2)\n",
    "    tfpl.DistributionLambda(lambda x: tfd.MultivariateNormalTriL(\n",
    "                            loc=x[..., :2], \n",
    "                            scale_tril=tfp.math.fill_triangular(x[...,2:])\n",
    "                            )\n",
    "                           )\n",
    "])\n",
    "\n",
    "lstm_model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going on, we take a sample from our dataset and pass it through the model to verify the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log probability shape is:\n",
      "(32, 5, 21)\n",
      "The true value's shape is:\n",
      "(32, 5, 21, 2)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"The log probability shape is:\")\n",
    "    print(lstm_model_1(x).log_prob(y).shape)\n",
    "    print(\"The true value's shape is:\")\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define also a custom loss function that computes the negative log likelihood over the time steps of prediction.  \n",
    "\n",
    "Recall that we would like to sum over the prediction time steps, which is the second axis in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negLog(y_true, y_pred):\n",
    "    return -tf.reduce_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `RMSProp` as in the paper to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_1.compile(loss=negLog, optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.003))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/var/folders/qd/mrmrksmj4v792bqkk9kgwv380000gn/T/ipykernel_62978/332767405.py\", line 2, in negLog  *\n        return -y_pred.log_prob(y_true)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1316, in log_prob  **\n        return self._call_log_prob(value, name, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1298, in _call_log_prob\n        return self._log_prob(value, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py\", line 114, in _log_prob\n        return self.tensor_distribution._log_prob(value, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py\", line 319, in _log_prob\n        self._per_mixture_component_log_prob(x), axis=-1)  # [S, B]\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py\", line 312, in _per_mixture_component_log_prob\n        log_prob_x = self.components_distribution.log_prob(x)  # [S, B, k]\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1316, in log_prob\n        return self._call_log_prob(value, name, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1298, in _call_log_prob\n        return self._log_prob(value, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py\", line 114, in _log_prob\n        return self.tensor_distribution._log_prob(value, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/distribution_util.py\", line 1362, in _fn\n        return fn(*args, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/mvn_linear_operator.py\", line 243, in _log_prob\n        return super(MultivariateNormalLinearOperator, self)._log_prob(x)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py\", line 358, in _log_prob\n        log_prob, _ = self.experimental_local_measure(\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py\", line 608, in experimental_local_measure\n        x = self.bijector.inverse(y, **bijector_kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/bijector.py\", line 1431, in inverse\n        return self._call_inverse(y, name, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/bijector.py\", line 1411, in _call_inverse\n        return self._cache.inverse(y, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 347, in inverse\n        return self._lookup(y, self._inverse_name, self._forward_name, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 493, in _lookup\n        self._invoke(input, forward_name, kwargs, attrs))\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 532, in _invoke\n        return getattr(self.bijector, fn_name)(input, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/composition.py\", line 614, in _inverse\n        return self._call_walk_inverse(\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/composition.py\", line 352, in _call_walk_inverse\n        return self._walk_inverse(step_fn, *args, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/chain.py\", line 149, in _walk_inverse\n        y = step_fn(bij, y, **kwargs.get(bij.name, {}))\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/composition.py\", line 615, in <lambda>\n        lambda b, y, **kwargs: b.inverse(y, **kwargs),\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/bijector.py\", line 1431, in inverse\n        return self._call_inverse(y, name, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/bijector.py\", line 1411, in _call_inverse\n        return self._cache.inverse(y, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 347, in inverse\n        return self._lookup(y, self._inverse_name, self._forward_name, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 493, in _lookup\n        self._invoke(input, forward_name, kwargs, attrs))\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 532, in _invoke\n        return getattr(self.bijector, fn_name)(input, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/shift.py\", line 85, in _inverse\n        return y - self.shift\n\n    ValueError: Dimensions must be equal, but are 21 and 32 for '{{node negLog/tensor_coercible_CONSTRUCTED_AT_sequential_4_mixture_same_family_3/log_prob/tensor_coercible/log_prob/chain_of_shift_of_scale_matvec_linear_operator/inverse/shift/inverse/sub}} = Sub[T=DT_FLOAT](negLog/tensor_coercible_CONSTRUCTED_AT_sequential_4_mixture_same_family_3/log_prob/pad_sample_dims/Reshape, sequential_4/mixture_same_family_3/MixtureSameFamily/multivariate_normal_tri_l_3/MultivariateNormalTriL/strided_slice)' with input shapes: [?,5,21,1,2], [32,21,2].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/customer/projects/Summer2022UROP/RecurrentNeuralNetworks/toy_example.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B162.55.253.134/Users/customer/projects/Summer2022UROP/RecurrentNeuralNetworks/toy_example.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m lstm_model\u001b[39m.\u001b[39;49mfit(train_ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mvalid_ds)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/qd/mrmrksmj4v792bqkk9kgwv380000gn/T/__autograph_generated_fileb9yg6n39.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/qd/mrmrksmj4v792bqkk9kgwv380000gn/T/__autograph_generated_file95op922r.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__negLog\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(y_pred)\u001b[39m.\u001b[39mlog_prob, (ag__\u001b[39m.\u001b[39mld(y_true),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py:1316\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_prob\u001b[39m(\u001b[39mself\u001b[39m, value, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlog_prob\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1305\u001b[0m   \u001b[39m\"\"\"Log probability density/mass function.\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \n\u001b[1;32m   1307\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[39m      values of type `self.dtype`.\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_log_prob(value, name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py:1298\u001b[0m, in \u001b[0;36mDistribution._call_log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name_and_control_scope(name, value, kwargs):\n\u001b[1;32m   1297\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_log_prob\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m-> 1298\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_prob(value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1299\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_prob\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1300\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prob(value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py:114\u001b[0m, in \u001b[0;36m_TensorCoercible._log_prob\u001b[0;34m(self, value, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_log_prob\u001b[39m(\u001b[39mself\u001b[39m, value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 114\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtensor_distribution\u001b[39m.\u001b[39;49m_log_prob(value, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py:319\u001b[0m, in \u001b[0;36m_MixtureSameFamily._log_prob\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_log_prob\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    318\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mreduce_logsumexp(\n\u001b[0;32m--> 319\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_per_mixture_component_log_prob(x), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py:312\u001b[0m, in \u001b[0;36m_MixtureSameFamily._per_mixture_component_log_prob\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39m\"\"\"Per mixture component log probability.\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \n\u001b[1;32m    300\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39m  number of mixture components.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    311\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pad_sample_dims(x)\n\u001b[0;32m--> 312\u001b[0m log_prob_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomponents_distribution\u001b[39m.\u001b[39;49mlog_prob(x)  \u001b[39m# [S, B, k]\u001b[39;00m\n\u001b[1;32m    313\u001b[0m log_mix_prob \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mlog_softmax(\n\u001b[1;32m    314\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmixture_distribution\u001b[39m.\u001b[39mlogits_parameter(), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# [B, k]\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39mreturn\u001b[39;00m log_prob_x \u001b[39m+\u001b[39m log_mix_prob\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py:1316\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_prob\u001b[39m(\u001b[39mself\u001b[39m, value, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlog_prob\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1305\u001b[0m   \u001b[39m\"\"\"Log probability density/mass function.\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \n\u001b[1;32m   1307\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[39m      values of type `self.dtype`.\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_log_prob(value, name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py:1298\u001b[0m, in \u001b[0;36mDistribution._call_log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name_and_control_scope(name, value, kwargs):\n\u001b[1;32m   1297\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_log_prob\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m-> 1298\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_prob(value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1299\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_prob\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1300\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prob(value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py:114\u001b[0m, in \u001b[0;36m_TensorCoercible._log_prob\u001b[0;34m(self, value, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_log_prob\u001b[39m(\u001b[39mself\u001b[39m, value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 114\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtensor_distribution\u001b[39m.\u001b[39;49m_log_prob(value, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/distribution_util.py:1362\u001b[0m, in \u001b[0;36mAppendDocstring.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[1;32m   1361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 1362\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/mvn_linear_operator.py:243\u001b[0m, in \u001b[0;36mMultivariateNormalLinearOperator._log_prob\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39m@distribution_util\u001b[39m\u001b[39m.\u001b[39mAppendDocstring(_mvn_sample_note)\n\u001b[1;32m    242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_log_prob\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 243\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(MultivariateNormalLinearOperator, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_log_prob(x)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py:358\u001b[0m, in \u001b[0;36m_TransformedDistribution._log_prob\u001b[0;34m(self, y, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_log_prob\u001b[39m(\u001b[39mself\u001b[39m, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    357\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     log_prob, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperimental_local_measure(\n\u001b[1;32m    359\u001b[0m         y, backward_compat\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    360\u001b[0m     \u001b[39mreturn\u001b[39;00m log_prob\n\u001b[1;32m    362\u001b[0m   \u001b[39m# TODO(b/197680518): Support base measure handling for non-injective\u001b[39;00m\n\u001b[1;32m    363\u001b[0m   \u001b[39m# bijectors.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py:608\u001b[0m, in \u001b[0;36m_TransformedDistribution.experimental_local_measure\u001b[0;34m(self, y, backward_compat, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m distribution_kwargs, bijector_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs_split_fn(kwargs)\n\u001b[1;32m    606\u001b[0m \u001b[39m# For caching to work, it is imperative that the bijector is the first to\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[39m# modify the input.\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbijector\u001b[39m.\u001b[39;49minverse(y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbijector_kwargs)\n\u001b[1;32m    609\u001b[0m event_ndims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector\u001b[39m.\u001b[39minverse_event_ndims(\n\u001b[1;32m    610\u001b[0m     tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(ps\u001b[39m.\u001b[39mrank_from_shape, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_shape_tensor(),\n\u001b[1;32m    611\u001b[0m                           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevent_shape), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbijector_kwargs)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/bijector.py:1431\u001b[0m, in \u001b[0;36mBijector.inverse\u001b[0;34m(self, y, name, **kwargs)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse\u001b[39m(\u001b[39mself\u001b[39m, y, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minverse\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1414\u001b[0m   \u001b[39m\"\"\"Returns the inverse `Bijector` evaluation, i.e., X = g^{-1}(Y).\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \n\u001b[1;32m   1416\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[39m    NotImplementedError: if `_inverse` is not implemented.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1431\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_inverse(y, name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/bijector.py:1411\u001b[0m, in \u001b[0;36mBijector._call_inverse\u001b[0;34m(self, y, name, **kwargs)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# No caching for non-injective\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inverse(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1411\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39minverse(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py:347\u001b[0m, in \u001b[0;36mBijectorCache.inverse\u001b[0;34m(self, y, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse\u001b[39m(\u001b[39mself\u001b[39m, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    337\u001b[0m   \u001b[39m\"\"\"Invokes the 'inverse' transformation, or looks up previous results.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \n\u001b[1;32m    339\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39m    The output of the bijector's `_inverse` method, or a cached result.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lookup(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inverse_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py:493\u001b[0m, in \u001b[0;36mBijectorCache._lookup\u001b[0;34m(self, input, forward_name, inverse_name, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m   output \u001b[39m=\u001b[39m output_ref()\n\u001b[1;32m    488\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m   \u001b[39m# Get the output structure, and declare a\u001b[39;00m\n\u001b[1;32m    490\u001b[0m   \u001b[39m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[1;32m    491\u001b[0m   output \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m    492\u001b[0m       _containerize,\n\u001b[0;32m--> 493\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke(\u001b[39minput\u001b[39;49m, forward_name, kwargs, attrs))\n\u001b[1;32m    494\u001b[0m   output_ref \u001b[39m=\u001b[39m WeakStructRef(\n\u001b[1;32m    495\u001b[0m       output,\n\u001b[1;32m    496\u001b[0m       subkey\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector_class, inverse_name, kwargs),\n\u001b[1;32m    497\u001b[0m       callback\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mmaybe_del)\n\u001b[1;32m    498\u001b[0m   \u001b[39m# Set the input->output mapping.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py:532\u001b[0m, in \u001b[0;36mBijectorCache._invoke\u001b[0;34m(self, input, fn_name, kwargs, attributes)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[39m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    531\u001b[0m   \u001b[39m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbijector, fn_name)(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/composition.py:614\u001b[0m, in \u001b[0;36mComposition._inverse\u001b[0;34m(self, y, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    611\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mInvert is not implemented for compositions of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    613\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mnon-injective bijectors.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 614\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_walk_inverse(\n\u001b[1;32m    615\u001b[0m     \u001b[39mlambda\u001b[39;49;00m b, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs: b\u001b[39m.\u001b[39;49minverse(y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),\n\u001b[1;32m    616\u001b[0m     y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/composition.py:352\u001b[0m, in \u001b[0;36mComposition._call_walk_inverse\u001b[0;34m(self, step_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m args \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(nest_util\u001b[39m.\u001b[39mcoerce_structure(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minverse_min_event_ndims, y)\n\u001b[1;32m    349\u001b[0m              \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m args)\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 352\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_walk_inverse(step_fn, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    354\u001b[0m \u001b[39m# Convert a tuple of structures to a structure of tuples. This\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[39m# allows `_walk` methods to route aligned structures of inputs/outputs\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39m# independently, obviates the need for conditional tuple unpacking.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m packed_args \u001b[39m=\u001b[39m pack_structs_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minverse_min_event_ndims, \u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/chain.py:149\u001b[0m, in \u001b[0;36m_Chain._walk_inverse\u001b[0;34m(self, step_fn, y, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m\"\"\"Applies `transform_fn` to `y` sequentially over nested bijectors.\"\"\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39mfor\u001b[39;00m bij \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bijectors:\n\u001b[0;32m--> 149\u001b[0m   y \u001b[39m=\u001b[39m step_fn(bij, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(bij\u001b[39m.\u001b[39;49mname, {}))\n\u001b[1;32m    150\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/composition.py:615\u001b[0m, in \u001b[0;36mComposition._inverse.<locals>.<lambda>\u001b[0;34m(b, y, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    611\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mInvert is not implemented for compositions of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    613\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mnon-injective bijectors.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    614\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_walk_inverse(\n\u001b[0;32m--> 615\u001b[0m     \u001b[39mlambda\u001b[39;00m b, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: b\u001b[39m.\u001b[39;49minverse(y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),\n\u001b[1;32m    616\u001b[0m     y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/bijector.py:1431\u001b[0m, in \u001b[0;36mBijector.inverse\u001b[0;34m(self, y, name, **kwargs)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse\u001b[39m(\u001b[39mself\u001b[39m, y, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minverse\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1414\u001b[0m   \u001b[39m\"\"\"Returns the inverse `Bijector` evaluation, i.e., X = g^{-1}(Y).\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \n\u001b[1;32m   1416\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[39m    NotImplementedError: if `_inverse` is not implemented.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1431\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_inverse(y, name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/bijector.py:1411\u001b[0m, in \u001b[0;36mBijector._call_inverse\u001b[0;34m(self, y, name, **kwargs)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# No caching for non-injective\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inverse(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1411\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39minverse(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py:347\u001b[0m, in \u001b[0;36mBijectorCache.inverse\u001b[0;34m(self, y, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse\u001b[39m(\u001b[39mself\u001b[39m, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    337\u001b[0m   \u001b[39m\"\"\"Invokes the 'inverse' transformation, or looks up previous results.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \n\u001b[1;32m    339\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39m    The output of the bijector's `_inverse` method, or a cached result.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lookup(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inverse_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py:493\u001b[0m, in \u001b[0;36mBijectorCache._lookup\u001b[0;34m(self, input, forward_name, inverse_name, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m   output \u001b[39m=\u001b[39m output_ref()\n\u001b[1;32m    488\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m   \u001b[39m# Get the output structure, and declare a\u001b[39;00m\n\u001b[1;32m    490\u001b[0m   \u001b[39m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[1;32m    491\u001b[0m   output \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m    492\u001b[0m       _containerize,\n\u001b[0;32m--> 493\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke(\u001b[39minput\u001b[39;49m, forward_name, kwargs, attrs))\n\u001b[1;32m    494\u001b[0m   output_ref \u001b[39m=\u001b[39m WeakStructRef(\n\u001b[1;32m    495\u001b[0m       output,\n\u001b[1;32m    496\u001b[0m       subkey\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector_class, inverse_name, kwargs),\n\u001b[1;32m    497\u001b[0m       callback\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mmaybe_del)\n\u001b[1;32m    498\u001b[0m   \u001b[39m# Set the input->output mapping.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py:532\u001b[0m, in \u001b[0;36mBijectorCache._invoke\u001b[0;34m(self, input, fn_name, kwargs, attributes)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[39m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    531\u001b[0m   \u001b[39m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbijector, fn_name)(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/shift.py:85\u001b[0m, in \u001b[0;36mShift._inverse\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_inverse\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m---> 85\u001b[0m   \u001b[39mreturn\u001b[39;00m y \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshift\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/var/folders/qd/mrmrksmj4v792bqkk9kgwv380000gn/T/ipykernel_62978/332767405.py\", line 2, in negLog  *\n        return -y_pred.log_prob(y_true)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1316, in log_prob  **\n        return self._call_log_prob(value, name, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1298, in _call_log_prob\n        return self._log_prob(value, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py\", line 114, in _log_prob\n        return self.tensor_distribution._log_prob(value, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py\", line 319, in _log_prob\n        self._per_mixture_component_log_prob(x), axis=-1)  # [S, B]\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py\", line 312, in _per_mixture_component_log_prob\n        log_prob_x = self.components_distribution.log_prob(x)  # [S, B, k]\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1316, in log_prob\n        return self._call_log_prob(value, name, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1298, in _call_log_prob\n        return self._log_prob(value, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py\", line 114, in _log_prob\n        return self.tensor_distribution._log_prob(value, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/distribution_util.py\", line 1362, in _fn\n        return fn(*args, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/mvn_linear_operator.py\", line 243, in _log_prob\n        return super(MultivariateNormalLinearOperator, self)._log_prob(x)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py\", line 358, in _log_prob\n        log_prob, _ = self.experimental_local_measure(\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py\", line 608, in experimental_local_measure\n        x = self.bijector.inverse(y, **bijector_kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/bijector.py\", line 1431, in inverse\n        return self._call_inverse(y, name, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/bijector.py\", line 1411, in _call_inverse\n        return self._cache.inverse(y, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 347, in inverse\n        return self._lookup(y, self._inverse_name, self._forward_name, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 493, in _lookup\n        self._invoke(input, forward_name, kwargs, attrs))\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 532, in _invoke\n        return getattr(self.bijector, fn_name)(input, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/composition.py\", line 614, in _inverse\n        return self._call_walk_inverse(\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/composition.py\", line 352, in _call_walk_inverse\n        return self._walk_inverse(step_fn, *args, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/chain.py\", line 149, in _walk_inverse\n        y = step_fn(bij, y, **kwargs.get(bij.name, {}))\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/composition.py\", line 615, in <lambda>\n        lambda b, y, **kwargs: b.inverse(y, **kwargs),\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/bijector.py\", line 1431, in inverse\n        return self._call_inverse(y, name, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/bijector.py\", line 1411, in _call_inverse\n        return self._cache.inverse(y, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 347, in inverse\n        return self._lookup(y, self._inverse_name, self._forward_name, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 493, in _lookup\n        self._invoke(input, forward_name, kwargs, attrs))\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/cache_util.py\", line 532, in _invoke\n        return getattr(self.bijector, fn_name)(input, **kwargs)\n    File \"/Users/customer/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/bijectors/shift.py\", line 85, in _inverse\n        return y - self.shift\n\n    ValueError: Dimensions must be equal, but are 21 and 32 for '{{node negLog/tensor_coercible_CONSTRUCTED_AT_sequential_4_mixture_same_family_3/log_prob/tensor_coercible/log_prob/chain_of_shift_of_scale_matvec_linear_operator/inverse/shift/inverse/sub}} = Sub[T=DT_FLOAT](negLog/tensor_coercible_CONSTRUCTED_AT_sequential_4_mixture_same_family_3/log_prob/pad_sample_dims/Reshape, sequential_4/mixture_same_family_3/MixtureSameFamily/multivariate_normal_tri_l_3/MultivariateNormalTriL/strided_slice)' with input shapes: [?,5,21,1,2], [32,21,2].\n"
     ]
    }
   ],
   "source": [
    "lstm_model_1.fit(train_ds, epochs=10, validation_data=valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63bf7c73efbaa60a9891fdddd1e96dd0cc596469d20228077150d640c222586"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
